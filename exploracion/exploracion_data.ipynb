{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final: Clasificación de tópicos de interés\n",
    "\n",
    "## Exploración de datos\n",
    "\n",
    "\n",
    "CC5113 - Aprendizaje Automático Bayesiano\n",
    "\n",
    "Profesor: Pablo Guerrero\n",
    "\n",
    "Autor: Martín Cornejo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SpanishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Interes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ojalá obliguen a Piñera a cerrar Punta Peuco, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piñera para crear base de apoyo moderada a su ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CNNChile MEMORIA 2014 Adimark: Piñera termina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PPK y Piñera en privado habrían conversado alg...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bachelet entregará el gobierno de Chile a Piñera</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Texto  Interes\n",
       "0  Ojalá obliguen a Piñera a cerrar Punta Peuco, ...    False\n",
       "1  Piñera para crear base de apoyo moderada a su ...     True\n",
       "2  @CNNChile MEMORIA 2014 Adimark: Piñera termina...     True\n",
       "3  PPK y Piñera en privado habrían conversado alg...    False\n",
       "4   Bachelet entregará el gobierno de Chile a Piñera     True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = np.genfromtxt('data_format.csv', delimiter='')\n",
    "datos=pd.read_csv('data_format.csv')\n",
    "print(datos.shape)\n",
    "#pdb.set_trace()\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiando strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazar tildes, caracteres especiales, todo a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ojala obliguen a piñera a cerrar punta peuco e...\n",
      "1    piñera para crear base de apoyo moderada a su ...\n",
      "2    cnnchile memoria  adimark piñera termina su go...\n",
      "3    ppk y piñera en privado habrian conversado alg...\n",
      "4     bachelet entregara el gobierno de chile a piñera\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "strings = datos.ix[:,0]\n",
    "\n",
    "def formatear(strings):\n",
    "    tildes = ['á','é','í','ó','ú']\n",
    "    vocales = ['a','e','i','o','u']\n",
    "\n",
    "    # tildes\n",
    "    for idx, vocal in enumerate(vocales):\n",
    "        strings = strings.str.replace(tildes[idx],vocal)\n",
    "\n",
    "    # caracteres especiales menos la ñ\n",
    "    strings = strings.str.replace('[^a-zñA-Z ]', \"\")\n",
    "\n",
    "    # todo a minusculas\n",
    "    strings = pd.Series(list(map(lambda x: x.lower(), strings)))\n",
    "    \n",
    "    return strings\n",
    "\n",
    "def oracionToStrArr(strings):\n",
    "    strings_arr = list(map(lambda x: x.split(), strings))\n",
    "    strings_arr = list(itertools.chain.from_iterable(strings_arr))    \n",
    "    return strings_arr\n",
    "\n",
    "print(formatear(strings).head())\n",
    "formated_array_data = oracionToStrArr(formatear(strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (piñer, 133)\n",
       "1        (que, 65)\n",
       "2        (con, 32)\n",
       "3    (sebasti, 30)\n",
       "4        (por, 27)\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SpanishStemmer()\n",
    "\n",
    "root_arr = list(map(lambda x: stemmer.stem(x), formated_array_data))\n",
    "\n",
    "def most_common(str_arr):\n",
    "  # get an iterable of (item, iterable) pairs\n",
    "  SL = sorted((x, i) for i, x in enumerate(str_arr))\n",
    "  list_pairs = []\n",
    "  #print('SL:', SL)\n",
    "  groups = itertools.groupby(SL, key=operator.itemgetter(0))\n",
    "    \n",
    "  # auxiliary function to get \"quality\" for an item\n",
    "  def _auxfun(g):\n",
    "    item, iterable = g\n",
    "    count = 0\n",
    "    min_index = len(str_arr)\n",
    "    for _, where in iterable:\n",
    "      count += 1\n",
    "      min_index = min(min_index, where)\n",
    "    list_pairs.append((item, count))\n",
    "    #print('item %r, count %r, minind %r' % (item, count, min_index))\n",
    "    return count, -min_index\n",
    "\n",
    "  return max(groups, key=_auxfun)[0], list_pairs\n",
    "\n",
    "stem_common, list_pairs = most_common(root_arr)\n",
    "\n",
    "pares_filtrados = list(filter(lambda x: len(x[0]) > 2, list_pairs))\n",
    "\n",
    "common_roots_sorted = pd.Series(sorted(pares_filtrados, key=lambda tup: tup[1], reverse=True))\n",
    "common_roots_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (piñera, 133)\n",
       "1     (sebastian, 30)\n",
       "2         (chile, 24)\n",
       "3          (este, 24)\n",
       "4    (presidente, 24)\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_lemma_dict(filename):\n",
    "   with open(filename, 'r') as document:\n",
    "       lemma_dict = {}\n",
    "       for line in document:\n",
    "           if line.strip():  # avoid empty lines\n",
    "               value, key = line.split(None, 1) # 'None' means 'all whitespace', which is the default\n",
    "               key = key.rstrip() # rstrip() to get rid of \\r and \\n\n",
    "               lemma_dict[key] = value # adding the flections as keys to the dict\n",
    "               lemma_dict[value] = value # adding also the base word as a key\n",
    "   return lemma_dict\n",
    "\n",
    "def query_word(lemma_dict):\n",
    "   word = input(\"\\nDame una palabra en español -> \")\n",
    "   try:\n",
    "      lemma = lemma_dict[word]\n",
    "      print(\"__your happy lemma is__: {}\".format(lemma))\n",
    "   except KeyError:\n",
    "      print(\"This word is not in the dictionary!\")\n",
    "   return query_word(lemma_dict)\n",
    "\n",
    "def lemmatiser(dict):\n",
    "    def lookup(word):\n",
    "        try:\n",
    "            lemma = dict[word]\n",
    "        except:\n",
    "            lemma = word\n",
    "        \n",
    "        return lemma\n",
    "    \n",
    "    return lookup\n",
    "\n",
    "resource_file = 'lemmatization-es.txt'\n",
    "lemmatiser_es = lemmatiser(create_lemma_dict(resource_file))\n",
    "#pdb.set_trace()\n",
    "\n",
    "def lematizar_ordenar_str_arr(str_arr):\n",
    "    lemma_arr = list(map(lemmatiser_es, str_arr))\n",
    "    common_lemma, pairs_lemma = most_common(lemma_arr)\n",
    "    pares_filtrados = list(filter(lambda x: len(x[0]) > 3, pairs_lemma))\n",
    "    common_lemma_sorted = sorted(pares_filtrados, key=lambda tup: tup[1], reverse=True)\n",
    "    return common_lemma_sorted\n",
    "\n",
    "pd.Series(lematizar_ordenar_str_arr(formated_array_data)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematizando por clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "datos_interes = datos[datos.Interes == True]\n",
    "#print(datos_interes.head())\n",
    "str_interes = datos_interes.ix[:,0]\n",
    "\n",
    "datos_no_interes = datos[datos.Interes == False]\n",
    "#print(datos_no_interes.head())\n",
    "str_no_interes = datos_no_interes.ix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           (piñera, 75)\n",
       "1       (presidente, 23)\n",
       "2        (sebastian, 23)\n",
       "3         (bachelet, 20)\n",
       "4            (chile, 20)\n",
       "5             (este, 15)\n",
       "6         (gobierno, 15)\n",
       "7            (comer, 13)\n",
       "8            (parir, 13)\n",
       "9             (mando, 9)\n",
       "10        (actividad, 6)\n",
       "11           (asumir, 6)\n",
       "12           (cambio, 6)\n",
       "13          (domingo, 6)\n",
       "14            (macri, 6)\n",
       "15           (mañana, 6)\n",
       "16            (nuevo, 6)\n",
       "17             (pais, 6)\n",
       "18          (reunion, 6)\n",
       "19            (tener, 6)\n",
       "20             (todo, 6)\n",
       "21         (asuncion, 5)\n",
       "22            (haber, 5)\n",
       "23           (llegar, 5)\n",
       "24            (poder, 5)\n",
       "25             (sera, 5)\n",
       "26            (ahora, 4)\n",
       "27          (chileno, 4)\n",
       "28            (decir, 4)\n",
       "29          (derecho, 4)\n",
       "             ...        \n",
       "435      (suramerica, 1)\n",
       "436         (tambien, 1)\n",
       "437           (tanto, 1)\n",
       "438    (tempranisimo, 1)\n",
       "439          (tendra, 1)\n",
       "440           (tirar, 1)\n",
       "441         (titeres, 1)\n",
       "442         (todavia, 1)\n",
       "443           (toser, 1)\n",
       "444        (tramitar, 1)\n",
       "445            (tras, 1)\n",
       "446      (trasandino, 1)\n",
       "447          (triste, 1)\n",
       "448          (tweter, 1)\n",
       "449         (twitter, 1)\n",
       "450         (ultimar, 1)\n",
       "451           (valpo, 1)\n",
       "452            (vaya, 1)\n",
       "453         (vendeta, 1)\n",
       "454           (venir, 1)\n",
       "455            (vida, 1)\n",
       "456           (video, 1)\n",
       "457           (viejo, 1)\n",
       "458            (vino, 1)\n",
       "459        (vitorear, 1)\n",
       "460           (vivir, 1)\n",
       "461           (votar, 1)\n",
       "462            (voto, 1)\n",
       "463          (vuelta, 1)\n",
       "464           (zurdo, 1)\n",
       "Length: 465, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lema_interes_ordenado = pd.Series(lematizar_ordenar_str_arr(oracionToStrArr(formatear(str_interes))))\n",
    "lema_no_interes_ordenado = pd.Series(lematizar_ordenar_str_arr(oracionToStrArr(formatear(str_no_interes))))\n",
    "\n",
    "lema_interes_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          (piñera, 58)\n",
       "1             (este, 9)\n",
       "2        (sebastian, 7)\n",
       "3             (bien, 6)\n",
       "4            (comer, 6)\n",
       "5           (cuando, 6)\n",
       "6            (haber, 6)\n",
       "7            (peuco, 6)\n",
       "8           (cerrar, 5)\n",
       "9            (punta, 5)\n",
       "10           (ahora, 4)\n",
       "11           (chile, 4)\n",
       "12           (ganar, 4)\n",
       "13           (parir, 4)\n",
       "14          (querer, 4)\n",
       "15        (academia, 3)\n",
       "16            (algo, 3)\n",
       "17        (bachelet, 3)\n",
       "18          (cierre, 3)\n",
       "19           (decir, 3)\n",
       "20           (dejar, 3)\n",
       "21     (diplomatica, 3)\n",
       "22           (estar, 3)\n",
       "23          (llegar, 3)\n",
       "24           (penal, 3)\n",
       "25           (piera, 3)\n",
       "26           (tener, 3)\n",
       "27           (votar, 3)\n",
       "28          (abogar, 2)\n",
       "29           (abrir, 2)\n",
       "             ...       \n",
       "346        (tampoco, 1)\n",
       "347          (tanto, 1)\n",
       "348           (tele, 1)\n",
       "349         (tiempo, 1)\n",
       "350          (tirar, 1)\n",
       "351          (tonda, 1)\n",
       "352          (toque, 1)\n",
       "353          (total, 1)\n",
       "354       (trabajar, 1)\n",
       "355        (traidor, 1)\n",
       "356         (tratar, 1)\n",
       "357        (travajo, 1)\n",
       "358          (trump, 1)\n",
       "359        (twitter, 1)\n",
       "360        (ultimar, 1)\n",
       "361       (vacancia, 1)\n",
       "362           (vaya, 1)\n",
       "363      (venezuela, 1)\n",
       "364       (ventilar, 1)\n",
       "365           (vice, 1)\n",
       "366       (victimar, 1)\n",
       "367         (victon, 1)\n",
       "368       (violador, 1)\n",
       "369        (volvera, 1)\n",
       "370         (volvio, 1)\n",
       "371           (voto, 1)\n",
       "372           (weon, 1)\n",
       "373      (xkjskskfj, 1)\n",
       "374          (ziiii, 1)\n",
       "375       (zurdosno, 1)\n",
       "Length: 376, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lema_no_interes_ordenado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
