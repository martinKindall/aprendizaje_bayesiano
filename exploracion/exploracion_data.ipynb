{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto: Clasificación de tópicos de interés\n",
    "\n",
    "## Entrega final\n",
    "\n",
    "\n",
    "CC5113 - Aprendizaje Automático Bayesiano\n",
    "\n",
    "Profesor: Pablo Guerrero\n",
    "\n",
    "Autor: Martín Cornejo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import label_propagation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Interes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ojalá obliguen a Piñera a cerrar Punta Peuco, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piñera para crear base de apoyo moderada a su ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CNNChile MEMORIA 2014 Adimark: Piñera termina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PPK y Piñera en privado habrían conversado alg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bachelet entregará el gobierno de Chile a Piñera</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Texto  Interes\n",
       "0  Ojalá obliguen a Piñera a cerrar Punta Peuco, ...        0\n",
       "1  Piñera para crear base de apoyo moderada a su ...        1\n",
       "2  @CNNChile MEMORIA 2014 Adimark: Piñera termina...        1\n",
       "3  PPK y Piñera en privado habrían conversado alg...        0\n",
       "4   Bachelet entregará el gobierno de Chile a Piñera        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos=pd.read_csv('data_format.csv')\n",
    "print(datos.shape)\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiando strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazar tildes, caracteres especiales, todo a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ojala obliguen a piñera a cerrar punta peuco e...\n",
      "1    piñera para crear base de apoyo moderada a su ...\n",
      "2    cnnchile memoria  adimark piñera termina su go...\n",
      "3    ppk y piñera en privado habrian conversado alg...\n",
      "4     bachelet entregara el gobierno de chile a piñera\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "strings = datos.ix[:,0]\n",
    "\n",
    "def formatear(strings):\n",
    "    tildes = ['á','é','í','ó','ú']\n",
    "    vocales = ['a','e','i','o','u']\n",
    "\n",
    "    # tildes\n",
    "    for idx, vocal in enumerate(vocales):\n",
    "        strings = strings.str.replace(tildes[idx],vocal)\n",
    "\n",
    "    # caracteres especiales menos la ñ\n",
    "    strings = strings.str.replace('[^a-zñA-Z ]', \"\")\n",
    "\n",
    "    # todo a minusculas\n",
    "    strings = pd.Series(list(map(lambda x: x.lower(), strings)))\n",
    "    \n",
    "    return strings\n",
    "\n",
    "def oracionToStrArr(strings):\n",
    "    strings_arr = list(map(lambda x: x.split(), strings))\n",
    "    #pdb.set_trace()\n",
    "    strings_arr = list(itertools.chain.from_iterable(strings_arr))    \n",
    "    return strings_arr\n",
    "\n",
    "print(formatear(strings).head())\n",
    "formated_array_data = oracionToStrArr(formatear(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_limpia = formatear(strings)\n",
    "data_limpia = pd.concat([data_limpia, datos.ix[:,1]], axis=1)\n",
    "data_limpia.head()\n",
    "data_limpia.to_csv(\"data_limpia.csv\", sep='\\t')\n",
    "datos_sin_et = pd.read_csv('data_format_unlabeled.csv')\n",
    "formatear(datos_sin_et.ix[:,0]).to_csv(\"data_limpia_unlabeled.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares (conteo y ordenar repetidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(str_arr):\n",
    "  # get an iterable of (item, iterable) pairs\n",
    "  SL = sorted((x, i) for i, x in enumerate(str_arr))\n",
    "  list_pairs = []\n",
    "  #print('SL:', SL)\n",
    "  groups = itertools.groupby(SL, key=operator.itemgetter(0))\n",
    "    \n",
    "  # auxiliary function to get \"quality\" for an item\n",
    "  def _auxfun(g):\n",
    "    item, iterable = g\n",
    "    count = 0\n",
    "    min_index = len(str_arr)\n",
    "    for _, where in iterable:\n",
    "      count += 1\n",
    "      min_index = min(min_index, where)\n",
    "    list_pairs.append((item, count))\n",
    "    #print('item %r, count %r, minind %r' % (item, count, min_index))\n",
    "    return count, -min_index\n",
    "\n",
    "  return max(groups, key=_auxfun)[0], list_pairs\n",
    "\n",
    "def aplicar_ordenar_str_arr(func, str_arr):\n",
    "    arr = list(map(func, str_arr))\n",
    "    common, pairs = most_common(arr)\n",
    "    pares_filtrados = list(filter(lambda x: len(x[0]) > 3, pairs))\n",
    "    common_sorted = sorted(pares_filtrados, key=lambda tup: tup[1], reverse=True)\n",
    "    return common_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando data por clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "datos_interes = datos[datos.Interes == True]\n",
    "#print(datos_interes.head())\n",
    "str_interes = datos_interes.ix[:,0]\n",
    "\n",
    "datos_no_interes = datos[datos.Interes == False]\n",
    "#print(datos_no_interes.head())\n",
    "str_no_interes = datos_no_interes.ix[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming por clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           (piñer, 95)\n",
       "1       (president, 31)\n",
       "2         (sebasti, 26)\n",
       "3         (gobiern, 25)\n",
       "4            (chil, 24)\n",
       "5        (bachelet, 21)\n",
       "6            (este, 10)\n",
       "7             (mand, 9)\n",
       "8            (mañan, 9)\n",
       "9             (pais, 9)\n",
       "10            (esta, 8)\n",
       "11         (reunion, 8)\n",
       "12            (asum, 7)\n",
       "13            (años, 7)\n",
       "14          (doming, 7)\n",
       "15           (activ, 6)\n",
       "16           (cambi, 6)\n",
       "17          (derech, 6)\n",
       "18           (macri, 6)\n",
       "19            (nuev, 6)\n",
       "20            (tien, 6)\n",
       "21        (asuncion, 5)\n",
       "22          (chilen, 5)\n",
       "23           (cierr, 5)\n",
       "24          (gobern, 5)\n",
       "25            (lleg, 5)\n",
       "26           (polit, 5)\n",
       "27            (pued, 5)\n",
       "28          (termin, 5)\n",
       "29            (ahor, 4)\n",
       "             ...       \n",
       "544         (todavi, 1)\n",
       "545           (trag, 1)\n",
       "546         (tramit, 1)\n",
       "547    (transparent, 1)\n",
       "548           (tras, 1)\n",
       "549      (trasandin, 1)\n",
       "550         (travaj, 1)\n",
       "551          (trist, 1)\n",
       "552           (twet, 1)\n",
       "553          (twitt, 1)\n",
       "554        (twitter, 1)\n",
       "555           (unas, 1)\n",
       "556           (unos, 1)\n",
       "557         (untong, 1)\n",
       "558         (urgent, 1)\n",
       "559           (valp, 1)\n",
       "560         (vendet, 1)\n",
       "561    (venezuelaqu, 1)\n",
       "562           (veni, 1)\n",
       "563           (vide, 1)\n",
       "564           (viej, 1)\n",
       "565           (vien, 1)\n",
       "566           (vist, 1)\n",
       "567          (vitor, 1)\n",
       "568           (volv, 1)\n",
       "569        (volveri, 1)\n",
       "570          (vuelt, 1)\n",
       "571         (vulner, 1)\n",
       "572           (weon, 1)\n",
       "573           (zurd, 1)\n",
       "Length: 574, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer_es = lambda x: SpanishStemmer().stem(x)\n",
    "\n",
    "stem_interes_ordenado = pd.Series(aplicar_ordenar_str_arr(stemmer_es,oracionToStrArr(formatear(str_interes))))\n",
    "stem_no_interes_ordenado = pd.Series(aplicar_ordenar_str_arr(stemmer_es,oracionToStrArr(formatear(str_no_interes))))\n",
    "\n",
    "stem_interes_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               (piñer, 88)\n",
       "1                (esta, 11)\n",
       "2                (ahor, 10)\n",
       "3                (punt, 10)\n",
       "4              (sebasti, 9)\n",
       "5                 (bien, 8)\n",
       "6                 (peuc, 8)\n",
       "7             (bachelet, 7)\n",
       "8                 (cerr, 7)\n",
       "9                 (cobr, 7)\n",
       "10           (president, 7)\n",
       "11                (chil, 6)\n",
       "12               (cuand, 6)\n",
       "13                (algo, 5)\n",
       "14               (culia, 5)\n",
       "15                (esto, 5)\n",
       "16               (quier, 5)\n",
       "17               (cierr, 4)\n",
       "18                (este, 4)\n",
       "19             (gobiern, 4)\n",
       "20              (ladron, 4)\n",
       "21                (mism, 4)\n",
       "22                (pier, 4)\n",
       "23                (tien, 4)\n",
       "24                (trat, 4)\n",
       "25             (academi, 3)\n",
       "26                (buen, 3)\n",
       "27     (cierrepuntapeuc, 3)\n",
       "28               (cumpl, 3)\n",
       "29              (derech, 3)\n",
       "               ...         \n",
       "544              (sujet, 1)\n",
       "545             (tampoc, 1)\n",
       "546               (tant, 1)\n",
       "547              (tendr, 1)\n",
       "548             (termin, 1)\n",
       "549               (tond, 1)\n",
       "550               (toqu, 1)\n",
       "551             (tortur, 1)\n",
       "552              (total, 1)\n",
       "553            (traidor, 1)\n",
       "554              (tramp, 1)\n",
       "555             (travaj, 1)\n",
       "556            (tremend, 1)\n",
       "557              (trump, 1)\n",
       "558              (twitt, 1)\n",
       "559              (ultim, 1)\n",
       "560            (vacanci, 1)\n",
       "561             (ventil, 1)\n",
       "562             (victon, 1)\n",
       "563               (viej, 1)\n",
       "564             (villeg, 1)\n",
       "565           (violador, 1)\n",
       "566            (vitacur, 1)\n",
       "567             (volver, 1)\n",
       "568              (volvi, 1)\n",
       "569          (xkjskskfj, 1)\n",
       "570             (yendos, 1)\n",
       "571              (ziiii, 1)\n",
       "572               (zorr, 1)\n",
       "573            (zurdosn, 1)\n",
       "Length: 574, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_no_interes_ordenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemma_dict(filename):\n",
    "   with open(filename, 'r') as document:\n",
    "       lemma_dict = {}\n",
    "       for line in document:\n",
    "           if line.strip():  # avoid empty lines\n",
    "               value, key = line.split(None, 1) # 'None' means 'all whitespace', which is the default\n",
    "               key = key.rstrip() # rstrip() to get rid of \\r and \\n\n",
    "               lemma_dict[key] = value # adding the flections as keys to the dict\n",
    "               lemma_dict[value] = value # adding also the base word as a key\n",
    "   return lemma_dict\n",
    "\n",
    "def query_word(lemma_dict):\n",
    "   word = input(\"\\nDame una palabra en español -> \")\n",
    "   try:\n",
    "      lemma = lemma_dict[word]\n",
    "      print(\"__your happy lemma is__: {}\".format(lemma))\n",
    "   except KeyError:\n",
    "      print(\"This word is not in the dictionary!\")\n",
    "   return query_word(lemma_dict)\n",
    "\n",
    "def lemmatiser(dict):\n",
    "    def lookup(word):\n",
    "        try:\n",
    "            lemma = dict[word]\n",
    "        except:\n",
    "            lemma = word\n",
    "        \n",
    "        return lemma\n",
    "    \n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematizando por clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "resource_file = 'lemmatization-es.txt'\n",
    "lemmatiser_es = lemmatiser(create_lemma_dict(resource_file))\n",
    "\n",
    "#pdb.set_trace()\n",
    "\n",
    "datos_interes = datos[datos.Interes == True]\n",
    "#print(datos_interes.head())\n",
    "str_interes = datos_interes.ix[:,0]\n",
    "\n",
    "datos_no_interes = datos[datos.Interes == False]\n",
    "#print(datos_no_interes.head())\n",
    "str_no_interes = datos_no_interes.ix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           (piñera, 95)\n",
       "1       (presidente, 29)\n",
       "2         (gobierno, 26)\n",
       "3        (sebastian, 26)\n",
       "4            (chile, 24)\n",
       "5             (este, 22)\n",
       "6         (bachelet, 21)\n",
       "7            (parir, 18)\n",
       "8            (comer, 17)\n",
       "9             (todo, 10)\n",
       "10            (hacer, 9)\n",
       "11            (mando, 9)\n",
       "12           (mañana, 9)\n",
       "13             (pais, 9)\n",
       "14            (tener, 9)\n",
       "15            (poder, 8)\n",
       "16           (asumir, 7)\n",
       "17          (domingo, 7)\n",
       "18            (tomar, 7)\n",
       "19        (actividad, 6)\n",
       "20           (cambio, 6)\n",
       "21           (entrar, 6)\n",
       "22            (haber, 6)\n",
       "23            (macri, 6)\n",
       "24            (nuevo, 6)\n",
       "25          (reunion, 6)\n",
       "26             (sera, 6)\n",
       "27         (asuncion, 5)\n",
       "28          (chileno, 5)\n",
       "29            (deber, 5)\n",
       "             ...        \n",
       "622        (tramitar, 1)\n",
       "623    (transparente, 1)\n",
       "624            (tras, 1)\n",
       "625      (trasandino, 1)\n",
       "626         (travajo, 1)\n",
       "627          (triste, 1)\n",
       "628          (tweter, 1)\n",
       "629         (twitter, 1)\n",
       "630       (twitteros, 1)\n",
       "631         (untongo, 1)\n",
       "632         (urgente, 1)\n",
       "633           (valpo, 1)\n",
       "634         (vendeta, 1)\n",
       "635    (venezuelaque, 1)\n",
       "636           (venia, 1)\n",
       "637           (venir, 1)\n",
       "638          (vestir, 1)\n",
       "639            (vida, 1)\n",
       "640           (video, 1)\n",
       "641           (viejo, 1)\n",
       "642            (vino, 1)\n",
       "643        (vitorear, 1)\n",
       "644           (vivir, 1)\n",
       "645          (volver, 1)\n",
       "646        (volveria, 1)\n",
       "647            (voto, 1)\n",
       "648          (vuelta, 1)\n",
       "649      (vulnerable, 1)\n",
       "650          (weones, 1)\n",
       "651           (zurdo, 1)\n",
       "Length: 652, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lema_interes_ordenado = pd.Series(aplicar_ordenar_str_arr(lemmatiser_es, oracionToStrArr(formatear(str_interes))))\n",
    "lema_no_interes_ordenado = pd.Series(aplicar_ordenar_str_arr(lemmatiser_es, oracionToStrArr(formatear(str_no_interes))))\n",
    "\n",
    "lema_interes_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         (piñera, 88)\n",
       "1           (este, 21)\n",
       "2          (ahora, 10)\n",
       "3          (haber, 10)\n",
       "4          (parir, 10)\n",
       "5       (sebastian, 9)\n",
       "6            (bien, 8)\n",
       "7           (comer, 8)\n",
       "8           (peuco, 8)\n",
       "9            (todo, 8)\n",
       "10       (bachelet, 7)\n",
       "11         (cerrar, 7)\n",
       "12          (decir, 7)\n",
       "13           (mano, 7)\n",
       "14          (punta, 7)\n",
       "15          (chile, 6)\n",
       "16          (cobre, 6)\n",
       "17         (cuando, 6)\n",
       "18          (dejar, 6)\n",
       "19     (presidente, 6)\n",
       "20         (querer, 6)\n",
       "21          (tener, 6)\n",
       "22           (algo, 5)\n",
       "23          (estar, 5)\n",
       "24          (hacer, 5)\n",
       "25         (culiao, 4)\n",
       "26          (ganar, 4)\n",
       "27       (gobierno, 4)\n",
       "28          (menos, 4)\n",
       "29          (mismo, 4)\n",
       "            ...       \n",
       "642         (total, 1)\n",
       "643      (trabajar, 1)\n",
       "644       (traidor, 1)\n",
       "645        (trampa, 1)\n",
       "646         (trato, 1)\n",
       "647       (travajo, 1)\n",
       "648      (tremendo, 1)\n",
       "649         (trump, 1)\n",
       "650       (twitter, 1)\n",
       "651       (ultimar, 1)\n",
       "652      (vacancia, 1)\n",
       "653          (vaya, 1)\n",
       "654      (ventilar, 1)\n",
       "655          (vice, 1)\n",
       "656        (victon, 1)\n",
       "657         (viejo, 1)\n",
       "658      (villegas, 1)\n",
       "659      (violador, 1)\n",
       "660      (vitacura, 1)\n",
       "661         (vivir, 1)\n",
       "662       (volvera, 1)\n",
       "663        (volvio, 1)\n",
       "664          (voto, 1)\n",
       "665          (weon, 1)\n",
       "666        (weones, 1)\n",
       "667     (xkjskskfj, 1)\n",
       "668       (yendose, 1)\n",
       "669         (ziiii, 1)\n",
       "670         (zorro, 1)\n",
       "671      (zurdosno, 1)\n",
       "Length: 672, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lema_no_interes_ordenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_es = np.genfromtxt('stop_words_es.txt', dtype='str')\n",
    "stop_words_es = formatear(pd.Series(stop_words_es))\n",
    "stop_words_es = list(map(lambda x: x, stop_words_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(min_df=2, max_features=50, stop_words=stop_words_es)\n",
    "data = formatear(strings)\n",
    "dtm_tf = tf_vectorizer.fit_transform(data)\n",
    "#pdb.set_trace()\n",
    "#True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        #pdb.set_trace()\n",
    "        message += \" \".join([feature_names[i] + \" \" + str(int(topic[i])) + \" \"\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])        \n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=2, max_iter=100,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=10,\n",
    "                                batch_size=10,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: piñera 104  gobierno 28  bachelet 28  peuco 12  punta 11  años 8 \n",
      "Topic #1: piñera 80  sebastian 34  presidente 31  chile 29  pais 13  da 11 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 6\n",
    "lda.fit(dtm_tf)\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.local/lib/python3.5/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el49161403512140501849341794472\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el49161403512140501849341794472_data = {\"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2], \"Term\": [\"asume\", \"asume\", \"asuncion\", \"asuncion\", \"a\\u00f1os\", \"bachelet\", \"bachelet\", \"cambio\", \"cambio\", \"cerrar\", \"chile\", \"chile\", \"cierre\", \"cierrepuntapeuco\", \"cobre\", \"da\", \"democracia\", \"democracia\", \"derecha\", \"derecha\", \"dia\", \"dia\", \"dira\", \"domingo\", \"domingo\", \"electo\", \"esto\", \"esto\", \"gobierno\", \"hace\", \"hay\", \"hay\", \"izquierda\", \"ja\", \"les\", \"les\", \"ley\", \"ley\", \"llego\", \"llego\", \"macri\", \"macri\", \"mandato\", \"mandato\", \"mando\", \"mando\", \"manos\", \"manos\", \"ma\\u00f1ana\", \"ma\\u00f1ana\", \"mejor\", \"mejor\", \"mismo\", \"moneda\", \"nuevo\", \"nuevo\", \"pais\", \"pais\", \"peuco\", \"piera\", \"piera\", \"pi\\u00f1era\", \"pi\\u00f1era\", \"pone\", \"pone\", \"ppk\", \"ppk\", \"presidente\", \"presidente\", \"punta\", \"reunion\", \"sea\", \"sea\", \"sebastian\", \"sebastian\", \"termina\", \"tiempos\", \"todos\", \"venezuela\", \"venezuela\"], \"Freq\": [0.18607338798385434, 0.9303669399192717, 0.1918207516987487, 0.9591037584937435, 0.9749606257166413, 0.9926550347719527, 0.036765001287850096, 0.9544742686056407, 0.1590790447676068, 0.9397842513377997, 0.03660571913798256, 0.988354416725529, 0.9704703704813127, 0.9247134815770511, 0.9717914862149373, 0.913060882940831, 0.9101985916226545, 0.1820397183245309, 0.878654374770958, 0.2196635936927395, 0.36650128849408425, 0.7330025769881685, 0.909754057303713, 0.1415375229465466, 0.8492251376792795, 0.8917190367766994, 0.9544903293976046, 0.13635576134251495, 0.9910001891969582, 0.9055215773068848, 0.9750704271202092, 0.12188380339002615, 0.9009905355424889, 0.9650612735912227, 0.1566102789083079, 0.7830513945415394, 0.1825115311826191, 0.9125576559130955, 0.44970745424327085, 0.44970745424327085, 0.14314450049145344, 0.8588670029487206, 0.9179715902881367, 0.18359431805762735, 0.8943316973874299, 0.11179146217342874, 0.1366694677376923, 0.8200168064261539, 0.09409478762315056, 0.9409478762315056, 0.2227824007924704, 0.8911296031698815, 0.8645504738419066, 0.920433219461475, 0.9553355209630288, 0.15922258682717144, 0.07922433822425111, 0.9506920586910133, 0.9314022629844952, 0.1398522785004172, 0.8391136710025032, 0.5714467471669217, 0.4300578612699514, 0.18659621125576642, 0.9329810562788321, 0.9654450503408554, 0.16090750839014256, 0.03399193686649996, 0.9857661691284988, 0.9164927149664672, 0.8805528736312745, 0.18554543115059813, 0.9277271557529907, 0.0314081224779625, 0.9736517968168374, 0.8937303148458414, 0.9251683000515086, 0.9415567826730937, 0.9461975220656663, 0.1576995870109444]}, \"plot.opts\": {\"ylab\": \"PC2\", \"xlab\": \"PC1\"}, \"R\": 30, \"topic.order\": [1, 2], \"mdsDat\": {\"y\": [0.0, 0.0], \"Freq\": [50.138280199066344, 49.86171980093365], \"cluster\": [1, 1], \"topics\": [1, 2], \"x\": [0.16741354507990885, -0.16741354507990885]}, \"tinfo\": {\"Term\": [\"sebastian\", \"presidente\", \"chile\", \"gobierno\", \"bachelet\", \"pais\", \"peuco\", \"da\", \"punta\", \"cobre\", \"ma\\u00f1ana\", \"a\\u00f1os\", \"reunion\", \"hay\", \"todos\", \"cierre\", \"ja\", \"esto\", \"macri\", \"cerrar\", \"domingo\", \"piera\", \"cambio\", \"venezuela\", \"nuevo\", \"ppk\", \"mando\", \"hace\", \"dira\", \"izquierda\", \"gobierno\", \"bachelet\", \"peuco\", \"punta\", \"a\\u00f1os\", \"cierre\", \"todos\", \"ja\", \"esto\", \"cerrar\", \"hay\", \"cambio\", \"hace\", \"cierrepuntapeuco\", \"venezuela\", \"izquierda\", \"ppk\", \"nuevo\", \"mandato\", \"democracia\", \"mismo\", \"termina\", \"derecha\", \"mando\", \"pi\\u00f1era\", \"llego\", \"dia\", \"manos\", \"les\", \"pone\", \"ma\\u00f1ana\", \"presidente\", \"chile\", \"sebastian\", \"pais\", \"da\", \"cobre\", \"reunion\", \"macri\", \"dira\", \"moneda\", \"tiempos\", \"ley\", \"asume\", \"domingo\", \"asuncion\", \"piera\", \"ma\\u00f1ana\", \"sea\", \"electo\", \"mejor\", \"pone\", \"les\", \"manos\", \"dia\", \"llego\", \"pi\\u00f1era\", \"mando\", \"derecha\", \"termina\", \"mismo\", \"nuevo\", \"ppk\", \"hay\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.4383, -2.4422, -3.2968, -3.3795, -3.6822, -3.8155, -3.7863, -3.8126, -3.8037, -3.9458, -3.699, -3.9737, -4.1035, -4.1262, -3.9674, -4.1013, -3.9938, -3.9848, -4.1296, -4.1212, -4.3014, -4.341, -4.3312, -3.7083, -1.154, -4.8944, -5.214, -5.3435, -5.6344, -6.0553, -5.6514, -2.3555, -2.432, -2.2818, -3.2257, -3.3715, -3.5454, -3.7072, -3.8536, -4.1057, -4.119, -4.1243, -4.114, -4.1368, -3.8649, -4.1692, -3.8563, -3.4625, -4.1486, -4.3357, -4.3366, -4.1843, -4.0532, -3.9523, -4.3867, -4.9522, -1.427, -5.3586, -6.3663, -6.441, -6.4622, -6.2577, -6.2832, -6.1927], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6719, 0.6697, 0.6494, 0.6458, 0.6281, 0.6238, 0.6227, 0.621, 0.6189, 0.6155, 0.6114, 0.6031, 0.6029, 0.6012, 0.6007, 0.6001, 0.5944, 0.5929, 0.5905, 0.5903, 0.5819, 0.5755, 0.5682, 0.5156, 0.1269, 0.0284, -0.4959, -0.9186, -1.0733, -1.319, -1.5997, 0.678, 0.6756, 0.6726, 0.6539, 0.6501, 0.6438, 0.6348, 0.6176, 0.6054, 0.6038, 0.6036, 0.6001, 0.5967, 0.595, 0.5947, 0.5916, 0.5892, 0.582, 0.5785, 0.577, 0.552, 0.5079, 0.4727, 0.3315, -0.0294, -0.1462, -1.1347, -1.4668, -1.5246, -1.579, -1.68, -1.695, -1.8823], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [31.0, 29.0, 27.0, 27.0, 27.0, 12.0, 11.0, 10.0, 10.0, 9.0, 10.0, 8.0, 7.0, 8.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 8.0, 5.0, 5.0, 5.0, 26.74602039365418, 26.64366738209639, 11.335647770710402, 10.43559346874532, 7.709931515002433, 6.74808125683225, 6.9479424210691585, 6.767400546682569, 6.827760551743436, 5.923562903005497, 7.581733902443993, 5.760672433868417, 5.059370078168695, 4.945542155942644, 5.797032932577892, 5.070313910384012, 5.645833517198321, 5.696894880142541, 4.928874598767225, 4.970284550923844, 4.151010872050589, 3.989768934570673, 4.02884399187484, 7.511109759601727, 96.61757524083752, 2.294013090973589, 1.6663967534920725, 1.464080309318398, 1.094478039823664, 0.718505597758291, 1.0760831927955927, 28.896415216488872, 26.76825124647261, 31.105603433795405, 12.102762218035933, 10.461453100019527, 8.791157570320895, 7.4781746524865556, 6.45980773782069, 5.020208115224494, 4.953981901944973, 4.927980806463115, 4.978694212039283, 4.866401455438259, 6.386817067163631, 4.71151420386841, 6.442326943976215, 9.551498050120838, 4.809477563032398, 3.988694179734105, 3.9852406906443125, 4.640660021254763, 5.290798884339657, 5.852842896377297, 3.7906099823308548, 2.153322573865297, 73.12702560062277, 1.4341171884870325, 0.5235717416070471, 0.48585411810596757, 0.4756709944513396, 0.5836210939224475, 0.5689168695602717, 0.6228016649276337], \"Total\": [31.0, 29.0, 27.0, 27.0, 27.0, 12.0, 11.0, 10.0, 10.0, 9.0, 10.0, 8.0, 7.0, 8.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 8.0, 5.0, 5.0, 5.0, 27.245201660232816, 27.199781448953047, 11.810149531688559, 10.911161471006217, 8.205459573425982, 7.212997133058574, 7.4344958570920125, 7.253425447227132, 7.333756858927865, 6.3844440800735835, 8.204535567371627, 6.286183082510122, 5.521679577057147, 5.407080246600015, 6.341170696474936, 5.549447860725292, 6.214750386758593, 6.280515974064989, 5.446791657714134, 5.493306676168617, 4.626681866501929, 4.4756230526766405, 4.5524157334818875, 8.94522694808876, 169.74460084146028, 4.447335664838886, 5.457006735822928, 7.316923205695694, 6.385276924163321, 5.359165619013054, 10.627581242916431, 29.418741389388995, 27.318135623304485, 31.83889774696497, 12.622383757494022, 10.952172179133896, 9.261245985035737, 7.949551025974167, 6.985947742083922, 5.495990877818967, 5.432224624536464, 5.404422092414564, 5.479105859888988, 5.374223637432616, 7.065264243586221, 5.213200298424872, 7.150401914953547, 10.627581242916431, 5.3895156232025405, 4.485717849490818, 4.488684907079061, 5.359165619013054, 6.385276924163321, 7.316923205695694, 5.457006735822928, 4.447335664838886, 169.74460084146028, 8.94522694808876, 4.5524157334818875, 4.4756230526766405, 4.626681866501929, 6.280515974064989, 6.214750386758593, 8.204535567371627]}, \"lambda.step\": 0.01};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el49161403512140501849341794472\", ldavis_el49161403512140501849341794472_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el49161403512140501849341794472\", ldavis_el49161403512140501849341794472_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el49161403512140501849341794472\", ldavis_el49161403512140501849341794472_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=           Freq  cluster  topics         x    y\n",
       "topic                                          \n",
       "0      50.13828        1       1  0.167414  0.0\n",
       "1      49.86172        1       2 -0.167414  0.0, topic_info=     Category       Freq        Term       Total  loglift  logprob\n",
       "term                                                              \n",
       "45    Default  31.000000   sebastian   31.000000  30.0000  30.0000\n",
       "41    Default  29.000000  presidente   29.000000  29.0000  29.0000\n",
       "6     Default  27.000000       chile   27.000000  28.0000  28.0000\n",
       "18    Default  27.000000    gobierno   27.000000  27.0000  27.0000\n",
       "3     Default  27.000000    bachelet   27.000000  26.0000  26.0000\n",
       "35    Default  12.000000        pais   12.000000  25.0000  25.0000\n",
       "36    Default  11.000000       peuco   11.000000  24.0000  24.0000\n",
       "10    Default  10.000000          da   10.000000  23.0000  23.0000\n",
       "42    Default  10.000000       punta   10.000000  22.0000  22.0000\n",
       "9     Default   9.000000       cobre    9.000000  21.0000  21.0000\n",
       "30    Default  10.000000      mañana   10.000000  20.0000  20.0000\n",
       "2     Default   8.000000        años    8.000000  19.0000  19.0000\n",
       "43    Default   7.000000     reunion    7.000000  18.0000  18.0000\n",
       "20    Default   8.000000         hay    8.000000  17.0000  17.0000\n",
       "48    Default   7.000000       todos    7.000000  16.0000  16.0000\n",
       "7     Default   7.000000      cierre    7.000000  15.0000  15.0000\n",
       "22    Default   7.000000          ja    7.000000  14.0000  14.0000\n",
       "17    Default   7.000000        esto    7.000000  13.0000  13.0000\n",
       "26    Default   6.000000       macri    6.000000  12.0000  12.0000\n",
       "5     Default   6.000000      cerrar    6.000000  11.0000  11.0000\n",
       "15    Default   7.000000     domingo    7.000000  10.0000  10.0000\n",
       "37    Default   7.000000       piera    7.000000   9.0000   9.0000\n",
       "4     Default   6.000000      cambio    6.000000   8.0000   8.0000\n",
       "49    Default   6.000000   venezuela    6.000000   7.0000   7.0000\n",
       "34    Default   6.000000       nuevo    6.000000   6.0000   6.0000\n",
       "40    Default   6.000000         ppk    6.000000   5.0000   5.0000\n",
       "28    Default   8.000000       mando    8.000000   4.0000   4.0000\n",
       "19    Default   5.000000        hace    5.000000   3.0000   3.0000\n",
       "14    Default   5.000000        dira    5.000000   2.0000   2.0000\n",
       "21    Default   5.000000   izquierda    5.000000   1.0000   1.0000\n",
       "...       ...        ...         ...         ...      ...      ...\n",
       "35     Topic2  12.102762        pais   12.622384   0.6539  -3.2257\n",
       "10     Topic2  10.461453          da   10.952172   0.6501  -3.3715\n",
       "9      Topic2   8.791158       cobre    9.261246   0.6438  -3.5454\n",
       "43     Topic2   7.478175     reunion    7.949551   0.6348  -3.7072\n",
       "26     Topic2   6.459808       macri    6.985948   0.6176  -3.8536\n",
       "14     Topic2   5.020208        dira    5.495991   0.6054  -4.1057\n",
       "33     Topic2   4.953982      moneda    5.432225   0.6038  -4.1190\n",
       "47     Topic2   4.927981     tiempos    5.404422   0.6036  -4.1243\n",
       "24     Topic2   4.978694         ley    5.479106   0.6001  -4.1140\n",
       "0      Topic2   4.866401       asume    5.374224   0.5967  -4.1368\n",
       "15     Topic2   6.386817     domingo    7.065264   0.5950  -3.8649\n",
       "1      Topic2   4.711514    asuncion    5.213200   0.5947  -4.1692\n",
       "37     Topic2   6.442327       piera    7.150402   0.5916  -3.8563\n",
       "30     Topic2   9.551498      mañana   10.627581   0.5892  -3.4625\n",
       "44     Topic2   4.809478         sea    5.389516   0.5820  -4.1486\n",
       "16     Topic2   3.988694      electo    4.485718   0.5785  -4.3357\n",
       "31     Topic2   3.985241       mejor    4.488685   0.5770  -4.3366\n",
       "39     Topic2   4.640660        pone    5.359166   0.5520  -4.1843\n",
       "23     Topic2   5.290799         les    6.385277   0.5079  -4.0532\n",
       "29     Topic2   5.852843       manos    7.316923   0.4727  -3.9523\n",
       "13     Topic2   3.790610         dia    5.457007   0.3315  -4.3867\n",
       "25     Topic2   2.153323       llego    4.447336  -0.0294  -4.9522\n",
       "38     Topic2  73.127026      piñera  169.744601  -0.1462  -1.4270\n",
       "28     Topic2   1.434117       mando    8.945227  -1.1347  -5.3586\n",
       "12     Topic2   0.523572     derecha    4.552416  -1.4668  -6.3663\n",
       "46     Topic2   0.485854     termina    4.475623  -1.5246  -6.4410\n",
       "32     Topic2   0.475671       mismo    4.626682  -1.5790  -6.4622\n",
       "34     Topic2   0.583621       nuevo    6.280516  -1.6800  -6.2577\n",
       "40     Topic2   0.568917         ppk    6.214750  -1.6950  -6.2832\n",
       "20     Topic2   0.622802         hay    8.204536  -1.8823  -6.1927\n",
       "\n",
       "[94 rows x 6 columns], token_table=      Topic      Freq              Term\n",
       "term                                   \n",
       "0         1  0.186073             asume\n",
       "0         2  0.930367             asume\n",
       "1         1  0.191821          asuncion\n",
       "1         2  0.959104          asuncion\n",
       "2         1  0.974961              años\n",
       "3         1  0.992655          bachelet\n",
       "3         2  0.036765          bachelet\n",
       "4         1  0.954474            cambio\n",
       "4         2  0.159079            cambio\n",
       "5         1  0.939784            cerrar\n",
       "6         1  0.036606             chile\n",
       "6         2  0.988354             chile\n",
       "7         1  0.970470            cierre\n",
       "8         1  0.924713  cierrepuntapeuco\n",
       "9         2  0.971791             cobre\n",
       "10        2  0.913061                da\n",
       "11        1  0.910199        democracia\n",
       "11        2  0.182040        democracia\n",
       "12        1  0.878654           derecha\n",
       "12        2  0.219664           derecha\n",
       "13        1  0.366501               dia\n",
       "13        2  0.733003               dia\n",
       "14        2  0.909754              dira\n",
       "15        1  0.141538           domingo\n",
       "15        2  0.849225           domingo\n",
       "16        2  0.891719            electo\n",
       "17        1  0.954490              esto\n",
       "17        2  0.136356              esto\n",
       "18        1  0.991000          gobierno\n",
       "19        1  0.905522              hace\n",
       "...     ...       ...               ...\n",
       "31        1  0.222782             mejor\n",
       "31        2  0.891130             mejor\n",
       "32        1  0.864550             mismo\n",
       "33        2  0.920433            moneda\n",
       "34        1  0.955336             nuevo\n",
       "34        2  0.159223             nuevo\n",
       "35        1  0.079224              pais\n",
       "35        2  0.950692              pais\n",
       "36        1  0.931402             peuco\n",
       "37        1  0.139852             piera\n",
       "37        2  0.839114             piera\n",
       "38        1  0.571447            piñera\n",
       "38        2  0.430058            piñera\n",
       "39        1  0.186596              pone\n",
       "39        2  0.932981              pone\n",
       "40        1  0.965445               ppk\n",
       "40        2  0.160908               ppk\n",
       "41        1  0.033992        presidente\n",
       "41        2  0.985766        presidente\n",
       "42        1  0.916493             punta\n",
       "43        2  0.880553           reunion\n",
       "44        1  0.185545               sea\n",
       "44        2  0.927727               sea\n",
       "45        1  0.031408         sebastian\n",
       "45        2  0.973652         sebastian\n",
       "46        1  0.893730           termina\n",
       "47        2  0.925168           tiempos\n",
       "48        1  0.941557             todos\n",
       "49        1  0.946198         venezuela\n",
       "49        2  0.157700         venezuela\n",
       "\n",
       "[80 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'ylab': 'PC2', 'xlab': 'PC1'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, dtm_tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo las frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 1057)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(datos.ix[:,0], datos.ix[:,1], test_size = 0.25, random_state = 4)\n",
    "\n",
    "tf_vectorizer = CountVectorizer(stop_words=stop_words_es)\n",
    "dtm_tf = tf_vectorizer.fit_transform(formatear(X_train))\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(dtm_tf)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando con Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BernoulliNB(fit_prior=False).fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6595744680851063"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_tweets = ['Viva Piñera', 'Creo que Piñera no tendrá buen desempeño en su nuevo gobierno', 'Piñera y Bachelet lideran gobiernos', 'Piñera y puntapeuco no se rinden']\n",
    "\n",
    "# Se extraen las características de los nuevos tweets\n",
    "dtm_tf_test = tf_vectorizer.transform(formatear(X_test))\n",
    "X_new_tfidf_test = tfidf_transformer.transform(dtm_tf_test)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf_test)\n",
    "#for tweet, prediction in zip(data_test, predicted):\n",
    "#    print('%r => %s' % (tweet, str(prediction)))\n",
    "\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['a', 'aca'...ty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words_es)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, random_state=42,\n",
    "                                            max_iter=5, tol=None))])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085106382978723"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Semi-supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando 40 datos sin etiquetar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.2, gamma=20, kernel='rbf', max_iter=30, n_jobs=1,\n",
       "        n_neighbors=7, tol=0.001)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_semi=pd.read_csv('data_format_unlabeled.csv')\n",
    "# X_train_semi, X_test_semi, y_train_semi, y_test_semi = train_test_split(datos_semi.ix[:,0], datos_semi.ix[:,1], test_size = 0.1, random_state = 4)\n",
    "X_train_s = datos_semi[(datos_semi.Interes == -1)]\n",
    "\n",
    "X_train_semi = pd.DataFrame(np.concatenate((X_train, X_train_s.ix[:,0]))).ix[:,0]\n",
    "y_train_semi = np.concatenate((y_train, X_train_s.ix[:,1]))\n",
    "\n",
    "tf_vectorizer_semi = CountVectorizer(stop_words=stop_words_es)\n",
    "dtm_tf_semi = tf_vectorizer_semi.fit_transform(formatear(X_train_semi))\n",
    "tfidf_transformer_semi = TfidfTransformer()\n",
    "X_train_tfidf_semi = tfidf_transformer_semi.fit_transform(dtm_tf_semi)\n",
    "\n",
    "dtm_tf_test_semi = tf_vectorizer_semi.transform(formatear(X_test))\n",
    "X_new_tfidf_test_semi = tfidf_transformer_semi.transform(dtm_tf_test_semi)\n",
    "\n",
    "text_clf_semi = label_propagation.LabelSpreading()\n",
    "text_clf_semi.fit(X_train_tfidf_semi.toarray(), y_train_semi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446808510638298"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_semi = text_clf_semi.predict(X_new_tfidf_test_semi)\n",
    "np.mean(predicted_semi == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando 80 datos sin etiquetar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.2, gamma=20, kernel='rbf', max_iter=30, n_jobs=1,\n",
       "        n_neighbors=7, tol=0.001)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_semi=pd.read_csv('data_format_unlabeled_extendida.csv')\n",
    "# X_train_semi, X_test_semi, y_train_semi, y_test_semi = train_test_split(datos_semi.ix[:,0], datos_semi.ix[:,1], test_size = 0.1, random_state = 4)\n",
    "X_train_s = datos_semi[(datos_semi.Interes == -1)]\n",
    "\n",
    "X_train_semi = pd.DataFrame(np.concatenate((X_train, X_train_s.ix[:,0]))).ix[:,0]\n",
    "y_train_semi = np.concatenate((y_train, X_train_s.ix[:,1]))\n",
    "\n",
    "tf_vectorizer_semi = CountVectorizer(stop_words=stop_words_es)\n",
    "dtm_tf_semi = tf_vectorizer_semi.fit_transform(formatear(X_train_semi))\n",
    "tfidf_transformer_semi = TfidfTransformer()\n",
    "X_train_tfidf_semi = tfidf_transformer_semi.fit_transform(dtm_tf_semi)\n",
    "\n",
    "dtm_tf_test_semi = tf_vectorizer_semi.transform(formatear(X_test))\n",
    "X_new_tfidf_test_semi = tfidf_transformer_semi.transform(dtm_tf_test_semi)\n",
    "\n",
    "text_clf_semi = label_propagation.LabelSpreading()\n",
    "text_clf_semi.fit(X_train_tfidf_semi.toarray(), y_train_semi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723404255319149"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_semi = text_clf_semi.predict(X_new_tfidf_test_semi)\n",
    "np.mean(predicted_semi == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando 1 dato sin etiquetar\n",
    "El motivo de agregar solo 1 dato es en realidad observar como predice el modelo de propagacio de etiquetas solo con los datos etiquetados, para tener una referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.2, gamma=20, kernel='rbf', max_iter=30, n_jobs=1,\n",
       "        n_neighbors=7, tol=0.001)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_semi=pd.read_csv('data_format_unlabeled_reducida.csv')\n",
    "# X_train_semi, X_test_semi, y_train_semi, y_test_semi = train_test_split(datos_semi.ix[:,0], datos_semi.ix[:,1], test_size = 0.1, random_state = 4)\n",
    "X_train_s = datos_semi[(datos_semi.Interes == -1)]\n",
    "\n",
    "X_train_semi = pd.DataFrame(np.concatenate((X_train, X_train_s.ix[:,0]))).ix[:,0]\n",
    "y_train_semi = np.concatenate((y_train, X_train_s.ix[:,1]))\n",
    "\n",
    "tf_vectorizer_semi = CountVectorizer(stop_words=stop_words_es)\n",
    "dtm_tf_semi = tf_vectorizer_semi.fit_transform(formatear(X_train_semi))\n",
    "tfidf_transformer_semi = TfidfTransformer()\n",
    "X_train_tfidf_semi = tfidf_transformer_semi.fit_transform(dtm_tf_semi)\n",
    "\n",
    "dtm_tf_test_semi = tf_vectorizer_semi.transform(formatear(X_test))\n",
    "X_new_tfidf_test_semi = tfidf_transformer_semi.transform(dtm_tf_test_semi)\n",
    "\n",
    "text_clf_semi = label_propagation.LabelSpreading()\n",
    "text_clf_semi.fit(X_train_tfidf_semi.toarray(), y_train_semi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7021276595744681"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_semi = text_clf_semi.predict(X_new_tfidf_test_semi)\n",
    "np.mean(predicted_semi == y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
